ðŸš€ PROMPT STRATÃ‰GIQUE NEXORA-CORE V8.0 FINAL

Enterprise ISP/WISP Platform â€“ Carrier Grade â€“ Production Ready

ðŸŽ¯ CONTEXTE & MISSION

Tu es un Architecte Logiciel Senior spÃ©cialisÃ© dans les plateformes ISP/WISP Carrier-Grade, expert en :

Go (Golang) production-grade pour systÃ¨mes critiques

Architecture hexagonale et microservices

RADIUS/AAA et gestion rÃ©seau tÃ©lÃ©coms

SaaS Multi-tenant B2B/B2B2C

SystÃ¨mes financiers sÃ©curisÃ©s

Mission : GÃ©nÃ¨re le module [NOM DU MODULE] pour Nexora-Core, une plateforme complÃ¨te de gestion ISP/WISP avec :

Multi-tenant (OpÃ©rateur â†’ Fournisseurs â†’ Revendeurs â†’ Clients)

Support 100k+ utilisateurs actifs

DisponibilitÃ© 99.95% (carrier-grade)

ConformitÃ© rÃ©glementaire (interception lÃ©gale, RGPD, retention)

ðŸ— ARCHITECTURE GLOBALE

Structure Projet (Respecter STRICTEMENT)

nexora-core/
â”œâ”€â”€ cmd/
â”‚ â”œâ”€â”€ api/ # API REST principale
â”‚ â”‚ â””â”€â”€ main.go
â”‚ â”œâ”€â”€ radius-server/ # Serveur RADIUS dÃ©diÃ©
â”‚ â”‚ â””â”€â”€ main.go
â”‚ â”œâ”€â”€ accounting-consumer/ # Consumer NATS accounting
â”‚ â”‚ â””â”€â”€ main.go
â”‚ â””â”€â”€ worker/ # Jobs async (billing, notifications)
â”‚ â””â”€â”€ main.go
â”‚
â”œâ”€â”€ internal/
â”‚ â”œâ”€â”€ adapters/
â”‚ â”‚ â”œâ”€â”€ primary/ # Driving Adapters
â”‚ â”‚ â”‚ â”œâ”€â”€ radius/
â”‚ â”‚ â”‚ â”‚ â”œâ”€â”€ server.go # Serveur RADIUS (layeh.com/radius)
â”‚ â”‚ â”‚ â”‚ â”œâ”€â”€ auth_handler.go
â”‚ â”‚ â”‚ â”‚ â”œâ”€â”€ acct_handler.go
â”‚ â”‚ â”‚ â”‚ â”œâ”€â”€ coa_handler.go # Change of Authorization
â”‚ â”‚ â”‚ â”‚ â””â”€â”€ drivers/ # Vendor-specific (VSA)
â”‚ â”‚ â”‚ â”‚ â”œâ”€â”€ mikrotik.go
â”‚ â”‚ â”‚ â”‚ â”œâ”€â”€ ubiquiti.go
â”‚ â”‚ â”‚ â”‚ â”œâ”€â”€ cisco.go
â”‚ â”‚ â”‚ â”‚ â””â”€â”€ huawei.go
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â”œâ”€â”€ web/
â”‚ â”‚ â”‚ â”‚ â”œâ”€â”€ server.go # HTTP/REST server
â”‚ â”‚ â”‚ â”‚ â”œâ”€â”€ middleware/
â”‚ â”‚ â”‚ â”‚ â”‚ â”œâ”€â”€ auth.go # JWT validation
â”‚ â”‚ â”‚ â”‚ â”‚ â”œâ”€â”€ rbac.go # Permission checks
â”‚ â”‚ â”‚ â”‚ â”‚ â”œâ”€â”€ rate_limit.go
â”‚ â”‚ â”‚ â”‚ â”‚ â””â”€â”€ audit.go # Audit trail
â”‚ â”‚ â”‚ â”‚ â”œâ”€â”€ handlers/
â”‚ â”‚ â”‚ â”‚ â”‚ â”œâ”€â”€ auth_handler.go
â”‚ â”‚ â”‚ â”‚ â”‚ â”œâ”€â”€ user_handler.go
â”‚ â”‚ â”‚ â”‚ â”‚ â”œâ”€â”€ billing_handler.go
â”‚ â”‚ â”‚ â”‚ â”‚ â”œâ”€â”€ ipam_handler.go
â”‚ â”‚ â”‚ â”‚ â”‚ â”œâ”€â”€ portal_handler.go
â”‚ â”‚ â”‚ â”‚ â”‚ â”œâ”€â”€ gis_handler.go
â”‚ â”‚ â”‚ â”‚ â”‚ â””â”€â”€ crm_handler.go
â”‚ â”‚ â”‚ â”‚ â””â”€â”€ dto/ # Data Transfer Objects
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â””â”€â”€ captive/
â”‚ â”‚ â”‚ â”œâ”€â”€ portal_server.go # Portail captif
â”‚ â”‚ â”‚ â””â”€â”€ templates/ # Templates dynamiques
â”‚ â”‚ â”‚
â”‚ â”‚ â””â”€â”€ secondary/ # Driven Adapters
â”‚ â”‚ â”œâ”€â”€ postgres/
â”‚ â”‚ â”‚ â”œâ”€â”€ adapter.go # Pool pgxpool
â”‚ â”‚ â”‚ â”œâ”€â”€ user_repository.go
â”‚ â”‚ â”‚ â”œâ”€â”€ plan_repository.go
â”‚ â”‚ â”‚ â”œâ”€â”€ nas_repository.go
â”‚ â”‚ â”‚ â”œâ”€â”€ billing_repository.go
â”‚ â”‚ â”‚ â”œâ”€â”€ wallet_repository.go
â”‚ â”‚ â”‚ â”œâ”€â”€ ipam_repository.go
â”‚ â”‚ â”‚ â”œâ”€â”€ audit_repository.go
â”‚ â”‚ â”‚ â”œâ”€â”€ portal_repository.go
â”‚ â”‚ â”‚ â”œâ”€â”€ gis_repository.go
â”‚ â”‚ â”‚ â”œâ”€â”€ crm_repository.go
â”‚ â”‚ â”‚ â””â”€â”€ transaction.go # Transaction manager
â”‚ â”‚ â”‚
â”‚ â”‚ â”œâ”€â”€ redis/
â”‚ â”‚ â”‚ â”œâ”€â”€ cache.go # Redis Sentinel client
â”‚ â”‚ â”‚ â”œâ”€â”€ session.go # Session management
â”‚ â”‚ â”‚ â”œâ”€â”€ ipam.go # IP pool management
â”‚ â”‚ â”‚ â””â”€â”€ rate_limiter.go
â”‚ â”‚ â”‚
â”‚ â”‚ â”œâ”€â”€ queue/
â”‚ â”‚ â”‚ â””â”€â”€ nats.go # NATS JetStream
â”‚ â”‚ â”‚
â”‚ â”‚ â”œâ”€â”€ payment/
â”‚ â”‚ â”‚ â”œâ”€â”€ stripe.go # Stripe adapter
â”‚ â”‚ â”‚ â”œâ”€â”€ paypal.go
â”‚ â”‚ â”‚ â”œâ”€â”€ mobile_money.go
â”‚ â”‚ â”‚ â””â”€â”€ factory.go # Payment gateway factory
â”‚ â”‚ â”‚
â”‚ â”‚ â”œâ”€â”€ notification/
â”‚ â”‚ â”‚ â”œâ”€â”€ email.go # SMTP/SendGrid
â”‚ â”‚ â”‚ â”œâ”€â”€ sms.go # Twilio/Nexmo
â”‚ â”‚ â”‚ â””â”€â”€ push.go # Firebase
â”‚ â”‚ â”‚
â”‚ â”‚ â”œâ”€â”€ storage/
â”‚ â”‚ â”‚ â””â”€â”€ s3.go # Document storage
â”‚ â”‚ â”‚
â”‚ â”‚ â””â”€â”€ gis/
â”‚ â”‚ â””â”€â”€ nominatim.go # Geocoding
â”‚ â”‚
â”‚ â””â”€â”€ core/
â”‚ â”œâ”€â”€ domain/
â”‚ â”‚ â”œâ”€â”€ user.go # User entity + value objects
â”‚ â”‚ â”œâ”€â”€ tenant.go # Multi-tenant hierarchy
â”‚ â”‚ â”œâ”€â”€ plan.go
â”‚ â”‚ â”œâ”€â”€ nas.go
â”‚ â”‚ â”œâ”€â”€ session.go # RADIUS session
â”‚ â”‚ â”œâ”€â”€ wallet.go # Financial wallet
â”‚ â”‚ â”œâ”€â”€ transaction.go
â”‚ â”‚ â”œâ”€â”€ invoice.go
â”‚ â”‚ â”œâ”€â”€ ip_pool.go # IPAM
â”‚ â”‚ â”œâ”€â”€ ip_allocation.go
â”‚ â”‚ â”œâ”€â”€ portal_template.go # Captive portal
â”‚ â”‚ â”œâ”€â”€ gis_location.go # GIS entities
â”‚ â”‚ â”œâ”€â”€ lead.go # CRM lead
â”‚ â”‚ â”œâ”€â”€ contract.go # CRM contract
â”‚ â”‚ â”œâ”€â”€ audit_log.go
â”‚ â”‚ â”œâ”€â”€ errors.go # Sentinel errors
â”‚ â”‚ â””â”€â”€ value_objects.go # Username, Email, MAC, etc.
â”‚ â”‚
â”‚ â”œâ”€â”€ ports/
â”‚ â”‚ â”œâ”€â”€ repositories.go # Repository interfaces
â”‚ â”‚ â”œâ”€â”€ services.go # Service interfaces
â”‚ â”‚ â”œâ”€â”€ payment.go # Payment gateway interface
â”‚ â”‚ â””â”€â”€ notification.go # Notification interface
â”‚ â”‚
â”‚ â””â”€â”€ services/
â”‚ â”œâ”€â”€ auth_service.go # Authentication + RBAC
â”‚ â”œâ”€â”€ radius_service.go # RADIUS business logic
â”‚ â”œâ”€â”€ accounting_service.go
â”‚ â”œâ”€â”€ billing_service.go # Invoicing + wallet
â”‚ â”œâ”€â”€ payment_service.go # Multi-gateway
â”‚ â”œâ”€â”€ ipam_service.go # IP management
â”‚ â”œâ”€â”€ portal_service.go # Captive portal
â”‚ â”œâ”€â”€ qos_service.go # QoS policies
â”‚ â”œâ”€â”€ gis_service.go # GIS + eligibility
â”‚ â”œâ”€â”€ crm_service.go # Lead management
â”‚ â”œâ”€â”€ notification_service.go
â”‚ â”œâ”€â”€ audit_service.go # Audit trail
â”‚ â”œâ”€â”€ cache_service.go
â”‚ â””â”€â”€ isp_service.go # Provider/reseller logic
â”‚
â”œâ”€â”€ migrations/
â”‚ â”œâ”€â”€ 001_initial_schema.up.sql
â”‚ â”œâ”€â”€ 001_initial_schema.down.sql
â”‚ â”œâ”€â”€ 002_add_billing.up.sql
â”‚ â”œâ”€â”€ 002_add_billing.down.sql
â”‚ â”œâ”€â”€ 003_add_ipam.up.sql
â”‚ â”œâ”€â”€ 003_add_ipam.down.sql
â”‚ â”œâ”€â”€ 004_add_gis.up.sql
â”‚ â”œâ”€â”€ 004_add_gis.down.sql
â”‚ â”œâ”€â”€ 005_add_crm.up.sql
â”‚ â””â”€â”€ 005_add_crm.down.sql
â”‚
â”œâ”€â”€ tests/
â”‚ â”œâ”€â”€ unit/
â”‚ â”‚ â”œâ”€â”€ auth_service_test.go
â”‚ â”‚ â”œâ”€â”€ billing_service_test.go
â”‚ â”‚ â””â”€â”€ ipam_service_test.go
â”‚ â”œâ”€â”€ integration/
â”‚ â”‚ â”œâ”€â”€ radius_test.go
â”‚ â”‚ â”œâ”€â”€ payment_test.go
â”‚ â”‚ â””â”€â”€ ipam_test.go
â”‚ â”œâ”€â”€ e2e/
â”‚ â”‚ â””â”€â”€ full_flow_test.go
â”‚ â””â”€â”€ benchmarks/
â”‚ â”œâ”€â”€ auth_bench_test.go
â”‚ â””â”€â”€ accounting_bench_test.go
â”‚
â”œâ”€â”€ docs/
â”‚ â”œâ”€â”€ ARCHITECTURE.md # C4 diagrams, ADR
â”‚ â”œâ”€â”€ RUNBOOK.md # Incident procedures
â”‚ â”œâ”€â”€ API.md # REST API documentation
â”‚ â”œâ”€â”€ RADIUS.md # RADIUS attributes
â”‚ â”œâ”€â”€ DEPLOYMENT.md # Deploy guide
â”‚ â”œâ”€â”€ SECURITY.md # Security practices
â”‚ â””â”€â”€ COMPLIANCE.md # Legal requirements
â”‚
â”œâ”€â”€ deployments/
â”‚ â”œâ”€â”€ docker-compose.yml # Dev environment
â”‚ â”œâ”€â”€ docker-compose.prod.yml # Production stack
â”‚ â”œâ”€â”€ kubernetes/
â”‚ â”‚ â”œâ”€â”€ namespace.yaml
â”‚ â”‚ â”œâ”€â”€ configmap.yaml
â”‚ â”‚ â”œâ”€â”€ secrets.yaml
â”‚ â”‚ â”œâ”€â”€ radius-deployment.yaml
â”‚ â”‚ â”œâ”€â”€ api-deployment.yaml
â”‚ â”‚ â”œâ”€â”€ worker-deployment.yaml
â”‚ â”‚ â”œâ”€â”€ consumer-deployment.yaml
â”‚ â”‚ â”œâ”€â”€ service.yaml
â”‚ â”‚ â”œâ”€â”€ ingress.yaml
â”‚ â”‚ â”œâ”€â”€ hpa.yaml # Horizontal Pod Autoscaler
â”‚ â”‚ â””â”€â”€ monitoring/
â”‚ â”‚ â”œâ”€â”€ prometheus.yaml
â”‚ â”‚ â””â”€â”€ grafana-dashboard.json
â”‚ â””â”€â”€ terraform/
â”‚ â”œâ”€â”€ main.tf
â”‚ â”œâ”€â”€ vpc.tf
â”‚ â”œâ”€â”€ rds.tf
â”‚ â”œâ”€â”€ elasticache.tf
â”‚ â””â”€â”€ eks.tf
â”‚
â”œâ”€â”€ configs/
â”‚ â”œâ”€â”€ config.dev.yaml
â”‚ â”œâ”€â”€ config.staging.yaml
â”‚ â””â”€â”€ config.prod.yaml
â”‚
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ migrate.sh # Database migrations
â”‚ â”œâ”€â”€ backup.sh # Automated backups
â”‚ â”œâ”€â”€ failover.sh # DR failover
â”‚ â”œâ”€â”€ seed_dev.sh # Dev data seeding
â”‚ â””â”€â”€ ci/
â”‚ â”œâ”€â”€ test.sh
â”‚ â”œâ”€â”€ build.sh
â”‚ â””â”€â”€ deploy.sh
â”‚
â”œâ”€â”€ web/ # Frontend PWA (optionnel)
â”‚ â”œâ”€â”€ public/
â”‚ â”œâ”€â”€ src/
â”‚ â”‚ â”œâ”€â”€ components/
â”‚ â”‚ â”œâ”€â”€ pages/
â”‚ â”‚ â”œâ”€â”€ services/
â”‚ â”‚ â””â”€â”€ store/
â”‚ â””â”€â”€ package.json
â”‚
â”œâ”€â”€ Makefile
â”œâ”€â”€ .golangci.yml
â”œâ”€â”€ .env.example
â”œâ”€â”€ go.mod
â”œâ”€â”€ go.sum
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

ðŸ” SÃ‰CURITÃ‰ & CONFORMITÃ‰ (CARRIER GRADE)

Authentication & Authorization

Multi-Factor Authentication:

Password: bcrypt cost=12

OTP: TOTP (RFC 6238) via Google Authenticator

SMS: Twilio/Nexmo avec rate limiting

Email: Verification links avec expiration

JWT Tokens:

Algorithme: RS256 (asymmetric)

Expiration: Access 15min, Refresh 7 jours

Revocation: Blacklist Redis avec TTL

Claims: user_id, tenant_id, role, permissions

RBAC (Role-Based Access Control):
HiÃ©rarchie:
- SuperAdmin: AccÃ¨s complet systÃ¨me
- TenantAdmin: Gestion tenant isolÃ©
- Provider: Gestion revendeurs + clients
- Reseller: Gestion clients uniquement
- Customer: AccÃ¨s profil + consommation
- Support: Read-only + actions limitÃ©es

Permissions granulaires:
- users.create, users.read, users.update, users.delete
- billing.read, billing.manage
- radius.disconnect, radius.change_plan
- audit.read (sensitive)
- ipam.allocate, ipam.release

Exemple implÃ©mentation RBAC :

package middleware

type Permission string

const (
PermUserCreate Permission = "users.create"
PermUserRead Permission = "users.read"
PermBillingManage Permission = "billing.manage"
PermRADIUSDisconnect Permission = "radius.disconnect"
)

var rolePermissions = map[string][]Permission{
"super_admin": {
PermUserCreate, PermUserRead, PermBillingManage, PermRADIUSDisconnect,
},
"provider": {
PermUserCreate, PermUserRead, PermBillingManage,
},
"reseller": {
PermUserRead,
},
"customer": {},
}

func RequirePermission(perm Permission) gin.HandlerFunc {
return func(c *gin.Context) {
claims := c.MustGet("claims").(*domain.TokenClaims)

if !hasPermission(claims.Role, perm) { c.JSON(403, gin.H{"error": "insufficient permissions"}) c.Abort() return } c.Next() } 

}

Audit Trail (Immuable)

Stockage:

Table: audit_logs (append-only)

Partition: Par mois (PostgreSQL partitioning)

Retention: 7 ans (conformitÃ© lÃ©gale)

ImmutabilitÃ©: Pas de UPDATE/DELETE

Ã‰vÃ©nements loggÃ©s:

Authentification: login, logout, failed_login

Financier: payment, refund, wallet_debit

RADIUS: session_start, session_stop, disconnect

Admin: user_create, user_delete, plan_change

IPAM: ip_allocate, ip_release

SystÃ¨me: config_change, backup_started

Format:

timestamp (nanosecond precision)

user_id, tenant_id, ip_address

action, resource_type, resource_id

old_value, new_value (JSON)

correlation_id (trace_id)

Schema SQL :

CREATE TABLE audit_logs (
id BIGSERIAL,
timestamp TIMESTAMP(6) NOT NULL DEFAULT NOW(),
user_id INTEGER,
tenant_id INTEGER NOT NULL,
ip_address INET,
action VARCHAR(50) NOT NULL,
resource_type VARCHAR(50) NOT NULL,
resource_id VARCHAR(255),
old_value JSONB,
new_value JSONB,
correlation_id UUID,
PRIMARY KEY (id, timestamp)
) PARTITION BY RANGE (timestamp);

CREATE INDEX idx_audit_tenant_time ON audit_logs(tenant_id, timestamp DESC);
CREATE INDEX idx_audit_user_action ON audit_logs(user_id, action);

-- Partition mensuelle automatique
CREATE TABLE audit_logs_2025_02 PARTITION OF audit_logs
FOR VALUES FROM ('2025-02-01') TO ('2025-03-01');

Interception LÃ©gale (Lawful Intercept)

ConformitÃ©:

CALEA (USA), ETSI (Europe), lois locales

Targets identifiÃ©s par autoritÃ© judiciaire

Logs immutables et chiffrÃ©s

AccÃ¨s strictement restreint

FonctionnalitÃ©s:

Capture sessions RADIUS (username, IP, dates)

Export trafic rÃ©seau (pcap) via mirroring

Blocage administratif immÃ©diat

Rapports pÃ©riodiques autoritÃ©s

SÃ©curitÃ©:

ClÃ© chiffrement hardware (HSM)

Dual control: 2 admin pour activation

Audit trail dÃ©diÃ© (qui a activÃ© quand)

Exemple service :

package services

type LawfulInterceptService struct {
repo ports.InterceptRepository
radius ports.RADIUSService
}

func (s *LawfulInterceptService) ActivateTarget(
ctx context.Context,
username string,
courtOrder string,
expiresAt time.Time,
) error {
// Validation dual control
if !s.validateDualControl(ctx) {
return errors.New("dual control required")
}

target := &domain.InterceptTarget{ Username: username, CourtOrder: courtOrder, // StockÃ© chiffrÃ© ActivatedAt: time.Now(), ExpiresAt: expiresAt, Status: "active", } // Enregistrer dans table sÃ©curisÃ©e if err := s.repo.Create(ctx, target); err != nil { return err } // Logger audit (immuable) s.auditLog(ctx, "lawful_intercept_activated", target) // Activer capture rÃ©seau (hors scope Go) // Appel API Ã©quipement rÃ©seau pour mirroring port return nil 

}

Protection DDoS & Rate Limiting

Layers:

Reverse Proxy: Cloudflare/Nginx avec limite globale

API Gateway: Kong/Traefik avec quota par tenant

Application: Redis-based token bucket

RADIUS: UDP stateless avec cache NAS

Limites par dÃ©faut:

API REST: 100 req/min/IP, 1000 req/min/tenant

RADIUS Auth: 50 auth/s/NAS

Payment: 10 transactions/min/user

Captive Portal: 20 logins/min/IP

DÃ©tection anomalies:

Spike auth failures (> 50/min) â†’ alerte

Payment fraud (montants suspects) â†’ blocage

Brute force login â†’ captcha + ban temporaire

ðŸ’³ GESTION FINANCIÃˆRE (BILLING & PAYMENTS)

Architecture Wallet Multi-Devise

EntitÃ©s:

Wallet: Compte virtuel par utilisateur/revendeur

Transaction: Mouvement atomique (debit/credit)

Invoice: Facture gÃ©nÃ©rÃ©e automatiquement

Commission: Partage revenus hiÃ©rarchique

FonctionnalitÃ©s:

Multi-currency: EUR, USD, XOF, etc.

Decimal precision: 4 dÃ©cimales (crypto-ready)

Double-entry bookkeeping (comptabilitÃ©)

Atomic transactions: ACID garanti

Idempotence: UUID transaction pour retry safe

Balance cache: Redis pour performance

Schema SQL :

CREATE TABLE wallets (
id SERIAL PRIMARY KEY,
user_id INTEGER NOT NULL REFERENCES users(id),
currency VARCHAR(3) NOT NULL DEFAULT 'EUR',
balance DECIMAL(18,4) NOT NULL DEFAULT 0 CHECK (balance >= 0),
locked_balance DECIMAL(18,4) NOT NULL DEFAULT 0,
created_at TIMESTAMP DEFAULT NOW(),
updated_at TIMESTAMP DEFAULT NOW(),

CONSTRAINT uk_user_currency UNIQUE(user_id, currency) 

);

CREATE TABLE transactions (
id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
wallet_id INTEGER NOT NULL REFERENCES wallets(id),
type VARCHAR(20) NOT NULL, -- credit, debit, commission
amount DECIMAL(18,4) NOT NULL,
balance_after DECIMAL(18,4) NOT NULL,
reference VARCHAR(255), -- Payment gateway ref
description TEXT,
metadata JSONB,
created_at TIMESTAMP DEFAULT NOW(),
idempotency_key VARCHAR(255) UNIQUE,

CHECK (amount > 0) 

);

CREATE INDEX idx_transactions_wallet_time ON transactions(wallet_id, created_at DESC);

CREATE TABLE invoices (
id SERIAL PRIMARY KEY,
tenant_id INTEGER NOT NULL,
user_id INTEGER NOT NULL,
invoice_number VARCHAR(50) NOT NULL UNIQUE,
amount DECIMAL(10,2) NOT NULL,
currency VARCHAR(3) NOT NULL,
status VARCHAR(20) NOT NULL, -- pending, paid, cancelled
due_date DATE NOT NULL,
paid_at TIMESTAMP,
pdf_url TEXT,
created_at TIMESTAMP DEFAULT NOW()
);

Multi-Gateway Payment

package payment

type Gateway interface {
CreatePayment(ctx context.Context, req *PaymentRequest) (*PaymentResponse, error)
VerifyWebhook(ctx context.Context, payload []byte, signature string) (*WebhookEvent, error)
Refund(ctx context.Context, paymentID string, amount decimal.Decimal) error
}

type PaymentRequest struct {
Amount decimal.Decimal
Currency string
UserID uint
Description string
ReturnURL string
WebhookURL string
Metadata map[string]string
}

// Factory pattern
func NewGateway(provider string, config Config) (Gateway, error) {
switch provider {
case "stripe":
return NewStripeGateway(config.StripeSecretKey), nil
case "paypal":
return NewPayPalGateway(config.PayPalClientID, config.PayPalSecret), nil
case "mobile_money":
return NewMobileMoneyGateway(config.MMAPI), nil
default:
return nil, fmt.Errorf("unknown provider: %s", provider)
}
}

Commission & Revenue Sharing

HiÃ©rarchie:
OpÃ©rateur (100%)
â†’ Fournisseur (80%)
â†’ Revendeur (60%)
â†’ Client final

Exemple:

Client paie 100 EUR

Revendeur reÃ§oit 60 EUR (commission 60%)

Fournisseur reÃ§oit 20 EUR (80% - 60%)

OpÃ©rateur reÃ§oit 20 EUR (100% - 80%)

Calcul automatique:

Lors du paiement client

CrÃ©dit wallet en cascade

Transaction atomique (ACID)

ImplÃ©mentation :

func (s *BillingService) ProcessPayment(ctx context.Context, payment *Payment) error {
// 1. DÃ©marrer transaction DB
tx, _ := s.db.BeginTx(ctx, nil)
defer tx.Rollback()

// 2. CrÃ©diter wallet client s.walletRepo.Credit(ctx, tx, payment.UserID, payment.Amount) // 3. Calculer et distribuer commissions hierarchy := s.getHierarchy(ctx, payment.UserID) for _, level := range hierarchy { commission := payment.Amount.Mul(level.CommissionRate) s.walletRepo.Credit(ctx, tx, level.UserID, commission) s.transactionRepo.Create(ctx, tx, &Transaction{ Type: "commission", Amount: commission, Description: fmt.Sprintf("Commission from %s", payment.UserID), }) } // 4. Commit return tx.Commit() 

}

Facturation Automatique

DÃ©clencheurs:

Fin de pÃ©riode (mensuel/annuel)

Consommation quota (pay-as-you-go)

Accounting RADIUS (data consumed)

Processus:

Calculer montant selon plan + consommation

GÃ©nÃ©rer invoice (PDF via HTML template)

DÃ©bit wallet ou appel payment gateway

Envoi email + push notification

Si Ã©chec: grace period 3 jours â†’ suspension

Template Invoice:

Logo revendeur

DÃ©tail consommation (data, temps)

TVA applicable selon pays

Mentions lÃ©gales obligatoires

ðŸŒ RADIUS & ACCOUNTING (Carrier Grade)

Isolation Stricte Multi-Tenant

Principe:

Chaque requÃªte RADIUS validÃ©e par NAS IP

NAS liÃ© Ã  1 tenant unique

User lookup scopÃ© par tenant_id

Impossible d'authentifier user d'un autre tenant

SÃ©curitÃ©:

Shared secret unique par NAS (Argon2id)

Message-Authenticator obligatoire

IP whitelist stricte

Rate limiting par NAS

Anti-Clonage & Session Unicity

MAC Binding (Sticky):

Lors premiÃ¨re auth: MAC â†’ User binding

Auths suivantes: validation MAC == binding

Si diffÃ©rent: reject avec raison "DEVICE_MISMATCH"

Option configurable par tenant

Session Limits:

Max 1 session simultanÃ©e (dÃ©faut)

Option multi-device pour entreprises (max 5)

DÃ©tection via Accounting Start

Auto-disconnect si limite atteinte

ImplÃ©mentation :

func (s *RADIUSService) CheckSessionLimit(ctx context.Context, user *User) error {
activeSessions := s.repo.CountActiveSessions(ctx, user.ID)

if activeSessions >= user.MaxSessions { // DÃ©connecter session la plus ancienne oldestSession := s.repo.GetOldestSession(ctx, user.ID) s.sendDisconnect(ctx, oldestSession) return errors.New("session limit reached, disconnected oldest") } return nil 

}

Accounting Asynchrone (NATS JetStream)

Architecture:
RADIUS Handler â†’ NATS Queue â†’ Consumer Pool â†’ DB Batch Insert

Avantages:

Ack immÃ©diat au NAS (< 10ms)

Pas de blocage si DB lente

RÃ©silience: retry automatique

ScalabilitÃ©: N consumers parallÃ¨les

Pattern:

RADIUS reÃ§oit Accounting-Request

Publish message NATS (idempotence key = Acct-Unique-ID)

Return Accounting-Response au NAS

Consumer pull batch 100 messages

Upsert DB (GREATEST pour Ã©viter rÃ©gression)

Ack messages aprÃ¨s succÃ¨s

Configuration NATS:

Stream: accounting.sessions

Retention: 7 jours

Replicas: 3 (HA)

Consumer group: accounting-writers

Max ack pending: 1000

CoA & Disconnect (RFC 3576)

Use Cases:

Changement plan en temps rÃ©el

Suspension pour impayÃ©

Ajustement vitesse (throttling)

DÃ©connexion administrateur

ImplÃ©mentation:

Packet CoA-Request vers NAS:3799/udp

Attributs: Session-ID, Speed-Limit, Action

Retry 3x avec backoff si timeout

Circuit breaker si NAS down

Exemple :

func (s *RADIUSService) ChangePlan(ctx context.Context, userID uint, newPlanID uint) error {
user := s.userRepo.GetByID(ctx, userID)
plan := s.planRepo.GetByID(ctx, newPlanID)

// Update DB s.userRepo.UpdatePlan(ctx, userID, newPlanID) // Si session active session := s.getActiveSession(ctx, userID) if session != nil { // Envoyer CoA pour changer vitesse return s.sendCoA(ctx, &CoARequest{ NASIP: session.NASIP, SessionID: session.RadiusSessionID, SpeedLimit: plan.SpeedLimit, }) } return nil 

}

ðŸŒ IPAM (IP Address Management)

Architecture Dual-Stack (IPv4 + IPv6)

Pools:

IPv4: 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16

IPv6: 2001:db8::/32 (exemple, adaptÃ© au prÃ©fixe ISP)

Types d'allocation:

Dynamic: DHCP-like, libÃ©rÃ©e Ã  dÃ©connexion

Static: IP fixe pour clients Business

Sticky: MÃªme IP si reconnexion < 24h

Prefix Delegation: /56 ou /64 pour clients FTTH

Exclusions:

Network address (.0)

Broadcast (.255)

Gateway (premier IP)

DNS servers (configurables)

Schema SQL :

CREATE TABLE ip_pools (
id SERIAL PRIMARY KEY,
tenant_id INTEGER NOT NULL,
name VARCHAR(100) NOT NULL,
cidr CIDR NOT NULL,
gateway INET,
dns_primary INET,
dns_secondary INET,
version INTEGER NOT NULL CHECK (version IN (4, 6)),
allocation_type VARCHAR(20) NOT NULL, -- dynamic, static, sticky
created_at TIMESTAMP DEFAULT NOW(),

CONSTRAINT uk_tenant_cidr UNIQUE(tenant_id, cidr) 

);

CREATE TABLE ip_allocations (
id SERIAL PRIMARY KEY,
pool_id INTEGER NOT NULL REFERENCES ip_pools(id),
ip_address INET NOT NULL,
user_id INTEGER REFERENCES users(id),
mac_address MACADDR,
session_id VARCHAR(255),
allocated_at TIMESTAMP DEFAULT NOW(),
released_at TIMESTAMP,
status VARCHAR(20) NOT NULL, -- allocated, reserved, released

CONSTRAINT uk_pool_ip UNIQUE(pool_id, ip_address) 

);

CREATE INDEX idx_ip_alloc_user ON ip_allocations(user_id) WHERE released_at IS NULL;
CREATE INDEX idx_ip_alloc_pool_status ON ip_allocations(pool_id, status);

Allocation via Redis (Performance)

StratÃ©gie:

Pool IP stockÃ© en Redis SET

Allocation = SPOP (atomic)

LibÃ©ration = SADD

Persistence DB asynchrone

Avantages:

Latence < 1ms (vs 10-50ms DB)

Race-condition free (Redis single-threaded)

ScalabilitÃ© horizontale RADIUS servers

Synchronisation:

Warmup: Load pool depuis DB â†’ Redis au dÃ©marrage

Accounting Stop: LibÃ©ration Redis + DB

Reconciliation job: Toutes les 5min sync Redis â†” DB

ImplÃ©mentation :

package ipam

type RedisIPAM struct {
redis *redis.Client
repo ports.IPAMRepository
}

func (r *RedisIPAM) AllocateIP(ctx context.Context, poolID uint, userID uint) (net.IP, error) {
key := fmt.Sprintf("pool:%d:available", poolID)

// Atomic pop from set ipStr, err := r.redis.SPop(ctx, key).Result() if err != nil { // Pool exhausted return nil, errors.New("no IP available") } ip := net.ParseIP(ipStr) // Async persist to DB go r.repo.CreateAllocation(context.Background(), &domain.IPAllocation{ PoolID: poolID, IPAddress: ip, UserID: userID, Status: "allocated", }) return ip, nil 

}

func (r *RedisIPAM) ReleaseIP(ctx context.Context, ip net.IP, poolID uint) error {
key := fmt.Sprintf("pool:%d:available", poolID)

// Return to pool r.redis.SAdd(ctx, key, ip.String()) // Update DB return r.repo.ReleaseAllocation(ctx, ip) 

}

IPv6 Prefix Delegation

Use Case:

Client FTTH reÃ§oit un /56 ou /64

Sous-rÃ©seau pour LAN client

Routage dÃ©lÃ©guÃ©

ImplÃ©mentation:

Pool /48 divisÃ© en prÃ©fixes /56

Attribution via DHCPv6-PD

Stockage allocation en DB

LibÃ©ration Ã  rÃ©siliation

ðŸŽ¨ PORTAIL CAPTIF DYNAMIQUE

Templates Multi-Tenant

Architecture:

Templates HTML/CSS stockÃ©s en DB

Variables: {{logo}}, {{title}}, {{tos_url}}, {{promo}}

Rendering: Go html/template

Cache: Redis par tenant_id

Personnalisation revendeur:

Logo (URL S3)

Couleurs primaire/secondaire (hex)

Texte accueil, CGU, messages

BanniÃ¨re publicitaire

Mode: User/Pass, SMS OTP, Social, Free+Ads

Modes d'authentification:

Classic: Username/Password

SMS OTP: NumÃ©ro â†’ code â†’ session temporaire

Social: Google/Facebook OAuth2

Gratuit avec pub: 30min gratuit aprÃ¨s vidÃ©o pub

Schema SQL :

CREATE TABLE portal_templates (
id SERIAL PRIMARY KEY,
tenant_id INTEGER NOT NULL,
name VARCHAR(100) NOT NULL,
logo_url TEXT,
primary_color VARCHAR(7) DEFAULT '#007bff',
secondary_color VARCHAR(7) DEFAULT '#6c757d',
welcome_text TEXT,
tos_url TEXT,
ad_banner_html TEXT,
auth_modes TEXT[] NOT NULL, -- {password, sms, social, free}
html_template TEXT NOT NULL,
css_template TEXT,
created_at TIMESTAMP DEFAULT NOW(),
updated_at TIMESTAMP DEFAULT NOW(),

CONSTRAINT uk_tenant_template UNIQUE(tenant_id, name) 

);

Rendu Dynamique

package captive

type PortalHandler struct {
service ports.PortalService
cache ports.CacheService
}

func (h *PortalHandler) RenderPortal(c *gin.Context) {
nasIP := c.Query("nas_ip")

// Get tenant from NAS nas := h.service.GetNASByIP(nasIP) // Get template (cache first) template := h.cache.GetPortalTemplate(nas.TenantID) if template == nil { template = h.service.GetActiveTemplate(nas.TenantID) h.cache.SetPortalTemplate(nas.TenantID, template, 10*time.Minute) } // Render data := map[string]interface{}{ "Logo": template.LogoURL, "Title": template.WelcomeText, "PrimaryColor": template.PrimaryColor, "AuthModes": template.AuthModes, } tmpl := html.Must(html.New("portal").Parse(template.HTMLTemplate)) tmpl.Execute(c.Writer, data) 

}

ðŸ“ GIS & CARTOGRAPHIE

EntitÃ©s GÃ©ographiques

ModÃ¨les:

POP (Point of Presence): Tour/site avec Ã©quipements

Coverage Zone: Polygone zone couverte

Customer Location: Point GPS client

Intervention: GÃ©olocalisation technicien

FonctionnalitÃ©s:

Visualisation carte (Leaflet/Mapbox)

Calcul Ã©ligibilitÃ© (distance, LoS, Fresnel)

Clustering clients par zone

Heatmap densitÃ© abonnÃ©s

Routing technicien (optimisation trajet)

Schema SQL :

CREATE EXTENSION IF NOT EXISTS postgis;

CREATE TABLE pops (
id SERIAL PRIMARY KEY,
tenant_id INTEGER NOT NULL,
name VARCHAR(100) NOT NULL,
location GEOGRAPHY(POINT, 4326) NOT NULL,
altitude INTEGER, -- mÃ¨tres
height_agl INTEGER, -- hauteur antenne
capacity_mbps INTEGER,
status VARCHAR(20) NOT NULL,
created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_pops_location ON pops USING GIST(location);

CREATE TABLE coverage_zones (
id SERIAL PRIMARY KEY,
pop_id INTEGER NOT NULL REFERENCES pops(id),
zone GEOGRAPHY(POLYGON, 4326) NOT NULL,
signal_strength INTEGER, -- dBm
technology VARCHAR(20), -- 2.4GHz, 5GHz, 60GHz
created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_coverage_zone ON coverage_zones USING GIST(zone);

CREATE TABLE customer_locations (
id SERIAL PRIMARY KEY,
user_id INTEGER NOT NULL REFERENCES users(id),
location GEOGRAPHY(POINT, 4326) NOT NULL,
address TEXT,
building_height INTEGER,
created_at TIMESTAMP DEFAULT NOW()
);

Calcul Ã‰ligibilitÃ©

package gis

type EligibilityService struct {
repo ports.GISRepository
}

type EligibilityResult struct {
Eligible bool
POPs []POP
Distance float64 // km
LineOfSight bool
FresnelZone float64 // % clearance
EstimatedSpeed int // Mbps
}

func (s *EligibilityService) CheckEligibility(
ctx context.Context,
location *geo.Point,
) (*EligibilityResult, error) {

// 1. Trouver POPs dans rayon 10km pops := s.repo.FindPOPsWithinRadius(ctx, location, 10000) if len(pops) == 0 { return &EligibilityResult{Eligible: false}, nil } // 2. Pour chaque POP, calculer LoS et Fresnel for _, pop := range pops { distance := geo.Distance(location, pop.Location) // Line of Sight (nÃ©cessite DEM - Digital Elevation Model) los := s.calculateLoS(location, pop.Location) // Fresnel zone clearance fresnel := s.calculateFresnel(location, pop.Location, 5.8) // 5.8 GHz if los && fresnel > 0.6 { return &EligibilityResult{ Eligible: true, POPs: []POP{pop}, Distance: distance / 1000, LineOfSight: true, FresnelZone: fresnel, EstimatedSpeed: s.estimateSpeed(distance, fresnel), }, nil } } return &EligibilityResult{Eligible: false}, nil 

}

ðŸ“ž CRM & LEAD MANAGEMENT

Pipeline Conversion

Ã‰tapes:

Lead: Prospect depuis formulaire Ã©ligibilitÃ©

Qualified: Ã‰ligible confirmÃ©, devis envoyÃ©

Proposal: Proposition commerciale en cours

Contract: Contrat signÃ© Ã©lectroniquement

Customer: Client actif

Automatisations:

Email accueil aprÃ¨s lead crÃ©ation

Relance si pas de rÃ©ponse 7 jours

Assignation technicien pour installation

Activation compte post-installation

Signature Ã‰lectronique:

IntÃ©gration DocuSign/HelloSign

Template contrat avec variables

Validation juridique

Schema SQL :

CREATE TABLE leads (
id SERIAL PRIMARY KEY,
tenant_id INTEGER NOT NULL,
first_name VARCHAR(100) NOT NULL,
last_name VARCHAR(100) NOT NULL,
email VARCHAR(255) NOT NULL,
phone VARCHAR(20),
address TEXT,
location GEOGRAPHY(POINT, 4326),
status VARCHAR(20) NOT NULL, -- lead, qualified, proposal, contract, customer, lost
source VARCHAR(50), -- website, referral, campaign
assigned_to INTEGER REFERENCES users(id),
eligibility JSONB, -- RÃ©sultat calcul Ã©ligibilitÃ©
created_at TIMESTAMP DEFAULT NOW(),
updated_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE contracts (
id SERIAL PRIMARY KEY,
lead_id INTEGER NOT NULL REFERENCES leads(id),
contract_number VARCHAR(50) NOT NULL UNIQUE,
plan_id INTEGER NOT NULL REFERENCES plans(id),
start_date DATE NOT NULL,
end_date DATE,
signed_at TIMESTAMP,
signature_url TEXT, -- DocuSign PDF
status VARCHAR(20) NOT NULL, -- draft, sent, signed, active, terminated
created_at TIMESTAMP DEFAULT NOW()
);

Service CRM

package services

type CRMService struct {
leadRepo ports.LeadRepository
contractRepo ports.ContractRepository
notification ports.NotificationService
docusign ports.DocumentSignService
}

func (s *CRMService) CreateLeadFromEligibility(
ctx context.Context,
req *CreateLeadRequest,
) (*domain.Lead, error) {

// 1. VÃ©rifier Ã©ligibilitÃ© eligibility := s.gisService.CheckEligibility(ctx, req.Location) lead := &domain.Lead{ TenantID: req.TenantID, FirstName: req.FirstName, LastName: req.LastName, Email: req.Email, Phone: req.Phone, Location: req.Location, Status: "lead", Eligibility: eligibility, } // 2. CrÃ©er lead if err := s.leadRepo.Create(ctx, lead); err != nil { return nil, err } // 3. Email accueil s.notification.SendEmail(ctx, &EmailRequest{ To: lead.Email, Subject: "Bienvenue chez [OpÃ©rateur]", Template: "welcome_lead", Data: map[string]interface{}{"Lead": lead}, }) // 4. Si Ã©ligible, auto-qualify if eligibility.Eligible { lead.Status = "qualified" s.leadRepo.Update(ctx, lead) // Assigner commercial s.assignSalesRep(ctx, lead) } return lead, nil 

}

func (s *CRMService) GenerateContract(
ctx context.Context,
leadID uint,
planID uint,
) (*domain.Contract, error) {

lead := s.leadRepo.GetByID(ctx, leadID) plan := s.planRepo.GetByID(ctx, planID) // GÃ©nÃ©rer numÃ©ro contrat contractNumber := s.generateContractNumber(lead.TenantID) contract := &domain.Contract{ LeadID: leadID, ContractNumber: contractNumber, PlanID: planID, StartDate: time.Now().AddDate(0, 0, 7), // +7 jours Status: "draft", } s.contractRepo.Create(ctx, contract) // Envoyer pour signature Ã©lectronique signatureURL, _ := s.docusign.SendForSignature(ctx, &SignatureRequest{ RecipientEmail: lead.Email, RecipientName: fmt.Sprintf("%s %s", lead.FirstName, lead.LastName), DocumentData: map[string]interface{}{ "ContractNumber": contractNumber, "Plan": plan.Name, "Price": plan.Price, }, Template: "isp_contract_template", }) contract.SignatureURL = signatureURL contract.Status = "sent" s.contractRepo.Update(ctx, contract) return contract, nil 

}

ðŸ“Š OBSERVABILITÃ‰ & MONITORING

MÃ©triques Prometheus (ComplÃ¨tes)

package metrics

import "github.com/prometheus/client_golang/prometheus"

var (
// RADIUS
radiusAuthTotal = prometheus.NewCounterVec(
prometheus.CounterOpts{
Name: "radius_auth_total",
Help: "Total RADIUS authentication attempts",
},
[]string{"tenant", "result", "reason"},
)

radiusAuthDuration = prometheus.NewHistogramVec( prometheus.HistogramOpts{ Name: "radius_auth_duration_seconds", Help: "RADIUS authentication latency", Buckets: []float64{.005, .01, .025, .05, .1, .25, .5, 1}, }, []string{"tenant"}, ) radiusActiveSessions = prometheus.NewGaugeVec( prometheus.GaugeOpts{ Name: "radius_active_sessions", Help: "Current active RADIUS sessions", }, []string{"tenant", "nas"}, ) radiusAccountingBytes = prometheus.NewCounterVec( prometheus.CounterOpts{ Name: "radius_accounting_bytes_total", Help: "Total bytes transferred (in/out)", }, []string{"tenant", "direction"}, ) // Billing paymentTotal = prometheus.NewCounterVec( prometheus.CounterOpts{ Name: "payment_total", Help: "Total payment attempts", }, []string{"tenant", "gateway", "status"}, ) paymentAmount = prometheus.NewHistogramVec( prometheus.HistogramOpts{ Name: "payment_amount_eur", Help: "Payment amount distribution", Buckets: []float64{5, 10, 20, 50, 100, 200, 500}, }, []string{"tenant", "gateway"}, ) walletBalance = prometheus.NewGaugeVec( prometheus.GaugeOpts{ Name: "wallet_balance_eur", Help: "Current wallet balance", }, []string{"tenant", "user_id"}, ) // IPAM ipPoolUtilization = prometheus.NewGaugeVec( prometheus.GaugeOpts{ Name: "ipam_pool_utilization_percent", Help: "IP pool utilization percentage", }, []string{"tenant", "pool_id"}, ) // Infrastructure dbPoolConns = prometheus.NewGaugeVec( prometheus.GaugeOpts{ Name: "db_pool_connections", Help: "Database connection pool state", }, []string{"state"}, // idle, active, waiting ) cacheHitRatio = prometheus.NewGaugeVec( prometheus.GaugeOpts{ Name: "cache_hit_ratio", Help: "Redis cache hit ratio", }, []string{"cache_type"}, ) queueDepth = prometheus.NewGaugeVec( prometheus.GaugeOpts{ Name: "queue_depth", Help: "NATS queue message pending", }, []string{"stream", "consumer"}, ) 

)

func init() {
prometheus.MustRegister(
radiusAuthTotal,
radiusAuthDuration,
radiusActiveSessions,
radiusAccountingBytes,
paymentTotal,
paymentAmount,
walletBalance,
ipPoolUtilization,
dbPoolConns,
cacheHitRatio,
queueDepth,
)
}

Dashboards Grafana

Dashboards:

RADIUS Operations:

Auth success rate (gauge)

Auth latency heatmap (p50/p95/p99)

Active sessions timeline

Accounting bytes (stacked area)

Top NAS by traffic

Billing & Finance:

Revenue today/week/month (stat)

Payment success rate

Top paying customers

Wallet balances distribution

Commission payouts

Infrastructure:

DB pool saturation

Redis hit ratio

Queue lag (NATS)

CPU/Memory per service

Network I/O

Business:

New signups timeline

Churn rate

ARPU (Average Revenue Per User)

Support ticket volume

GIS coverage heatmap

Alerting (PagerDuty/Opsgenie)

Critical Alerts:

Auth failure rate > 10% (5min) â†’ Page on-call

DB pool exhausted > 2min â†’ Page DBA

Payment gateway down > 1min â†’ Page billing team

RADIUS server down > 30s â†’ Page network team

IPAM pool > 90% full â†’ Email network ops

Warning Alerts:

Auth latency p95 > 100ms â†’ Slack channel

Queue lag > 10k messages â†’ Slack channel

Disk usage > 80% â†’ Email sysadmin

Unusual traffic spike â†’ Slack security

Business Alerts:

Daily revenue < threshold â†’ Email finance

Churn rate spike â†’ Email customer success

New contract signed â†’ Slack sales

ðŸ§ª TESTS & QUALITÃ‰

Strategy de Tests

Layers:

Unit Tests (80%+ coverage):

Domain logic pure

Services avec mocks

Value objects validation

Integration Tests:

Repository avec testcontainers

RADIUS packet flow

Payment gateway sandbox

E2E Tests:

User signup â†’ payment â†’ activation â†’ session

Admin create reseller â†’ reseller create customer

Performance Tests:

k6 load testing (1000 auth/s)

DB query benchmarks

Memory leak detection

Security Tests:

OWASP ZAP scanning

SQL injection attempts

JWT tampering

Rate limit bypass

Exemple Test Unitaire

package services_test

func TestBillingService_ProcessPayment(t *testing.T) {
tests := []struct {
name string
payment *domain.Payment
setupMocks func(*mocks.MockWalletRepo, *mocks.MockPaymentGateway)
wantErr bool
wantWalletCredit decimal.Decimal
}{
{
name: "successful payment with commission",
payment: &domain.Payment{
UserID: 1,
Amount: decimal.NewFromInt(100),
Currency: "EUR",
Gateway: "stripe",
},
setupMocks: func(repo *mocks.MockWalletRepo, gw *mocks.MockPaymentGateway) {
gw.EXPECT().
CreatePayment(gomock.Any(), gomock.Any()).
Return(&PaymentResponse{Status: "success"}, nil)

repo.EXPECT(). Credit(gomock.Any(), gomock.Any(), uint(1), decimal.NewFromInt(100)). Return(nil) // Commission revendeur (60%) repo.EXPECT(). Credit(gomock.Any(), gomock.Any(), uint(2), decimal.NewFromInt(60)). Return(nil) }, wantErr: false, wantWalletCredit: decimal.NewFromInt(100), }, { name: "payment gateway failure", payment: &domain.Payment{ UserID: 1, Amount: decimal.NewFromInt(50), Gateway: "stripe", }, setupMocks: func(repo *mocks.MockWalletRepo, gw *mocks.MockPaymentGateway) { gw.EXPECT(). CreatePayment(gomock.Any(), gomock.Any()). Return(nil, errors.New("gateway timeout")) }, wantErr: true, }, } for _, tt := range tests { t.Run(tt.name, func(t *testing.T) { ctrl := gomock.NewController(t) defer ctrl.Finish() mockRepo := mocks.NewMockWalletRepo(ctrl) mockGateway := mocks.NewMockPaymentGateway(ctrl) tt.setupMocks(mockRepo, mockGateway) service := services.NewBillingService(mockRepo, mockGateway) err := service.ProcessPayment(context.Background(), tt.payment) if (err != nil) != tt.wantErr { t.Errorf("ProcessPayment() error = %v, wantErr %v", err, tt.wantErr) } }) } 

}

Integration Test (Testcontainers)

package integration_test

func TestUserRepository_MultiTenant(t *testing.T) {
// Setup PostgreSQL container
ctx := context.Background()

postgres, err := testcontainers.GenericContainer(ctx, testcontainers.GenericContainerRequest{ ContainerRequest: testcontainers.ContainerRequest{ Image: "postgres:15-alpine", ExposedPorts: []string{"5432/tcp"}, Env: map[string]string{ "POSTGRES_USER": "test", "POSTGRES_PASSWORD": "test", "POSTGRES_DB": "nexora_test", }, WaitingFor: wait.ForListeningPort("5432/tcp"), }, Started: true, }) require.NoError(t, err) defer postgres.Terminate(ctx) // Get connection host, _ := postgres.Host(ctx) port, _ := postgres.MappedPort(ctx, "5432") dsn := fmt.Sprintf("postgres://test:test@%s:%s/nexora_test", host, port.Port()) pool, _ := pgxpool.New(ctx, dsn) defer pool.Close() // Run migrations runMigrations(pool) repo := postgres.NewUserRepository(pool) // Test: Users from different tenants are isolated user1 := &domain.User{Username: "alice@tenant1", TenantID: 1} user2 := &domain.User{Username: "alice@tenant2", TenantID: 2} repo.Create(ctx, user1) repo.Create(ctx, user2) // Fetch tenant 1 retrieved, err := repo.GetByUsername(ctx, 1, "alice@tenant1") require.NoError(t, err) assert.Equal(t, uint(1), retrieved.TenantID) // Fetch tenant 2 retrieved, err = repo.GetByUsername(ctx, 2, "alice@tenant2") require.NoError(t, err) assert.Equal(t, uint(2), retrieved.TenantID) // Cross-tenant fetch should fail _, err = repo.GetByUsername(ctx, 1, "alice@tenant2") assert.Error(t, err) 

}

ðŸš€ DEPLOYMENT & CI/CD

Docker Multi-Stage

Build stage

FROM golang:1.22-alpine AS builder

WORKDIR /app

Dependencies

COPY go.mod go.sum ./
RUN go mod download

Build

COPY . .
RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo \
-ldflags="-w -s" \
-o /nexora-api ./cmd/api

Runtime stage

FROM alpine:latest

RUN apk --no-cache add ca-certificates tzdata

WORKDIR /root/

COPY --from=builder /nexora-api .
COPY configs/ ./configs/
COPY migrations/ ./migrations/

EXPOSE 8080 1812/udp 1813/udp

CMD ["./nexora-api"]

Kubernetes Manifests

deployments/kubernetes/api-deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
name: nexora-api
namespace: nexora
spec:
replicas: 3
selector:
matchLabels:
app: nexora-api
template:
metadata:
labels:
app: nexora-api
spec:
containers:
- name: api
image: nexora/api:v1.0.0
ports:
- containerPort: 8080
env:
- name: DB_HOST
valueFrom:
secretKeyRef:
name: nexora-secrets
key: db-host
- name: DB_PASSWORD
valueFrom:
secretKeyRef:
name: nexora-secrets
key: db-password
- name: REDIS_ADDR
value: "redis-sentinel:26379"
- name: NATS_URL
value: "nats://nats:4222"
resources:
requests:
memory: "512Mi"
cpu: "500m"
limits:
memory: "1Gi"
cpu: "1000m"
livenessProbe:
httpGet:
path: /health
port: 8080
initialDelaySeconds: 30
periodSeconds: 10
readinessProbe:
httpGet:
path: /ready
port: 8080
initialDelaySeconds: 10
periodSeconds: 5

apiVersion: v1
kind: Service
metadata:
name: nexora-api
namespace: nexora
spec:
type: LoadBalancer
ports:

port: 80
targetPort: 8080
name: http
selector:
app: nexora-api

HPA (Horizontal Pod Autoscaler)

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
name: nexora-api-hpa
namespace: nexora
spec:
scaleTargetRef:
apiVersion: apps/v1
kind: Deployment
name: nexora-api
minReplicas: 3
maxReplicas: 10
metrics:

type: Resource
resource:
name: cpu
target:
type: Utilization
averageUtilization: 70

type: Resource
resource:
name: memory
target:
type: Utilization
averageUtilization: 80

CI/CD Pipeline (GitHub Actions)

.github/workflows/ci-cd.yml

name: CI/CD Pipeline

on:
push:
branches: [main, develop]
pull_request:
branches: [main]

jobs:
test:
runs-on: ubuntu-latest
steps:
- uses: actions/checkout@v3

- name: Setup Go uses: actions/setup-go@v4 with: go-version: '1.22' - name: Install dependencies run: go mod download - name: Run tests run: | go test -v -race -coverprofile=coverage.out ./... go tool cover -func=coverage.out - name: Run linter run: | go install github.com/golangci/golangci-lint/cmd/golangci-lint@latest golangci-lint run - name: Security scan run: | go install github.com/securego/gosec/v2/cmd/gosec@latest gosec ./... 

build:
needs: test
runs-on: ubuntu-latest
if: github.ref == 'refs/heads/main'
steps:
- uses: actions/checkout@v3

- name: Build Docker image run: | docker build -t nexora/api:${{ github.sha }} . docker tag nexora/api:${{ github.sha }} nexora/api:latest - name: Push to registry run: | echo ${{ secrets.DOCKER_PASSWORD }} | docker login -u ${{ secrets.DOCKER_USERNAME }} --password-stdin docker push nexora/api:${{ github.sha }} docker push nexora/api:latest 

deploy:
needs: build
runs-on: ubuntu-latest
if: github.ref == 'refs/heads/main'
steps:
- name: Deploy to Kubernetes
run: |
kubectl set image deployment/nexora-api \
api=nexora/api:${{ github.sha }} \
--namespace=nexora \
--record

- name: Verify deployment run: | kubectl rollout status deployment/nexora-api -n nexora kubectl get pods -n nexora 

ðŸ“‹ LIVRABLES FINAUX

Code Complet

âœ… internal/domain/ (15 fichiers)
âœ… internal/ports/ (5 fichiers)
âœ… internal/services/ (12 fichiers)
âœ… internal/adapters/primary/ (10 fichiers)
âœ… internal/adapters/secondary/ (15 fichiers)
âœ… cmd/ (4 binaires)
âœ… migrations/ (10 fichiers up/down)

Tests

âœ… tests/unit/ (80%+ coverage)
âœ… tests/integration/ (testcontainers)
âœ… tests/e2e/ (scÃ©narios complets)
âœ… tests/benchmarks/ (performance)

Documentation

âœ… docs/ARCHITECTURE.md (C4 + ADR)
âœ… docs/RUNBOOK.md (incidents)
âœ… docs/API.md (REST endpoints)
âœ… docs/RADIUS.md (attributes)
âœ… docs/SECURITY.md (practices)
âœ… docs/COMPLIANCE.md (legal)
âœ… README.md (quick start)

Deployment

âœ… docker-compose.yml (dev)
âœ… docker-compose.prod.yml (prod stack)
âœ… kubernetes/ (manifests complets)
âœ… terraform/ (infrastructure as code)
âœ… .github/workflows/ (CI/CD)

Tooling

âœ… Makefile (build, test, migrate, lint)
âœ… .golangci.yml (linter config)
âœ… scripts/ (backup, failover, seed)

ðŸŽ¯ OBJECTIF FINAL

Le module gÃ©nÃ©rÃ© avec ce prompt V8.0 doit Ãªtre :

âœ… Carrier-Grade - OpÃ©rateur tÃ©lÃ©coms production
âœ… Multi-Tenant B2B/B2B2C - OpÃ©rateur â†’ Fournisseurs â†’ Revendeurs â†’ Clients
âœ… Scalable 100k+ users - Architecture horizontale
âœ… DisponibilitÃ© 99.95% - HA + DR + monitoring
âœ… Conforme lÃ©gal - RGPD + interception + retention
âœ… Complet mÃ©tier - RADIUS + Billing + IPAM + GIS + CRM + Portail
âœ… SÃ©curisÃ© Zero Trust - MFA + RBAC + Audit + Chiffrement
âœ… Observable - Metrics + Logs + Tracing + Alerting
âœ… Testable - 80%+ coverage + E2E
âœ… Deployable - Docker + K8s + Terraform + CI/CD

RAPPEL CARRIER-GRADE (OBLIGATOIRE)

Le code gÃ©nÃ©rÃ© DOIT :

âš ï¸ Compiler sans erreur

âš ï¸ Contenir tous les imports nÃ©cessaires

âš ï¸ Ne contenir aucun import inutilisÃ©

âš ï¸ Utiliser regexp.MustCompile uniquement au niveau package

âš ï¸ Ne pas utiliser de variables globales mutables

âš ï¸ ÃŠtre thread-safe

âš ï¸ Propager context.Context partout

âš ï¸ GÃ©rer proprement les erreurs (wrapping avec %w)

âš ï¸ Avoir des tests qui compilent et passent

âš ï¸ Passer golangci-lint

âš ï¸ ÃŠtre compatible Graceful Shutdown

âš ï¸ Ne pas contenir de TODO

âš ï¸ Ne pas contenir de panic()

âš ï¸ ÃŠtre prÃªt pour la production carrier-grade ISP system

Retien bien ceci et garde le en mÃ©moire